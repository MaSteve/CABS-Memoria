\chapter{Introducción}
La idea de programa ha cambiado mucho a lo largo de la historia de la informática. En un principio, la mayoría de sistemas solo podían hacerse cargo de una única secuencia de instrucciones a la vez, lo que durante muchos años fue una limitación para los programas concurrentes.\\

Hoy en día, con los avances en el hardware de las últimas décadas, las máquinas que usamos a diario permiten la ejecución simultanea de varios hilos de ejecución en sus procesadores multinúcleo. Es por esto que la mayoría de productos en el mercado están desarrollados con la idea de ejecutar varios hilos en paralelo.\\

El principal problema que presenta la ejecución en paralelo es la presencia de una memoria compartida sobre la que los distintos hilos de ejecución pueden realizar modificaciones en cualquier instante de tiempo. Asociada a esta situación se encuentran los principales problemas de la programación concurrente como son los deadlocks, las carreras de datos o comportamientos impredecibles del programa.\\

Esto lleva a que la cantidad de errores presentes en un programa concurrente sea mucho mayor que la que uno pueda cometer al desarrollar un programa con un solo hilo de ejecución. Sobre estos problemas se han abordado diferentes soluciones como pueden ser el uso de semáforos y cerrojos o implementaciones de algoritmos de más bajo nivel como el tie-breaker, pero el uso de estos mecanismos puede ser bastante complejo.\\

Es por esto, que en el terreno de la programación concurrente se sigue investigando para encontrar un modo definitivo que permita solucionar los problemas en el desarrollo de aplicaciones o que al menos permita indicar al programador si su código presenta posibles errores relacionados con una mala gestión de la concurrencia.\\

Teóricamente, un programa se considera concurrente cuando cuenta con varias secuencias de instrucciones que pueden actuar sobre una memoria o estado y en el que la selección de qué hilo o secuencia se ejecutará a continuación es escogida con cierta arbitrariedad. Más allá de tener varias instrucciones ejecutándose a la vez en el mismo procesador, nos podemos limitar a que solo una única instrucción se ejecuta a la vez, pero, desconocemos el orden en el que se ejecutará con respecto al resto de instrucciones. Esta noción es conocida como \emph{interleaving} o entrelazamiento.\\

Uno de los primeros asuntos estudiados es determinar, por ejemplo, el estado final al que se llega ejecutando un programa concurrente. Se entiende que la presencia de interleavings introduce cierta incertidumbre como podemos ver en el siguiente ejemplo:

\begin{lstlisting}
  int var;

  proc f1() {
    var := 1;
  }

  proc f2() {
    var := 2;
  }
\end{lstlisting}

Supongamos que $f1$ y $f2$ se ejecutan en paralelo. Cada una de ellas cuenta con una única instrucción de asignación sobre la variable $var$. Nuestro ordenador elegirá cuál de las dos secuencias ejecutar en el siguiente paso de un modo aleatorio. Digamos que primero se escoge la secuencia de $f1$ con lo que llegamos a un estado en el que $var = 1$. A continuación elegirá $f2$, puesto que la otra secuencia se habrá quedado vacía, y destruirá el valor anteriormente asignado llegando al estado en el que $var = 2$.\\

Sin embargo, si la decisión hubiera sido tomada al contrario y la primera secuencia ejecutada fuera la de $f2$, el valor destruido sería el $2$ y terminaríamos con $var = 1$. ¿Qué estado produce nuestro programa entonces? La respuesta es que ambos, dependiendo de la ejecución. ¿Generalmente queremos esta situación? La respuesta suele ser que no.\\

En este ejemplo determinar los posibles estados finales de un programa es sencillo, pero no es el caso general. Los programas concurrentes padecen de una explosión exponencial en el número de interleavings en proporción al número de hilos y al número de instrucciones con los que cuentan.\\

¿Y esta explosión exponencial afecta también al número de estados posibles a lo que se puede llegar con la ejecución de un programa concurrente cualquiera? La respuesta es depende. Veamos otro ejemplo.

\begin{lstlisting}
  int var1;
  int var2;

  proc f1() {
    var1 := 1;  # 1
    var1 := 2;  # 2
  }

  proc f2() {
    var2 := 2;  # 3
    var2 := 1;  # 4
  }
\end{lstlisting}

En esta ocasión podemos notar que cada uno de los procedimientos asigna únicamente a una de las variables luego el estado final al que llega este programa es al que cumple que $var1 = 2$ y $var2 = 1$. Sin embargo, el número de interleavings es $5$, los que se corresponden con las secuencias ``$1, 2, 3, 4$'', ``$1, 3, 2, 4$'', ``$3, 1, 2, 4$'', ``$3, 1, 4, 2$'' y ``$3, 4, 1, 2$''.\\

Luego aparentemente no todos los interleavings tienen la misma importancia y algunos de ellos (o en el caso del ejemplo anterior todos) son equivalentes entre sí lo que resulta en que estudiar todas las posibles ejecuciones a veces puede no implicar una amplia variedad de estados finales.\\

Pero, por el momento, olvidémonos de cuándo o no es necesario analizarlas todas ellas y pensemos en cómo de difícil puede presentársenos este problema.\\

Empecemos por una instrucción como
\begin{lstlisting}
  int var = var1 + var2;
\end{lstlisting}
El significado que se puede dar de esta instrucción depende de qué consideramos que se puede ejecutar en paralelo y qué no. Es lo que se conoce como grano del paralelismo.\\

Generalmente se hablan de dos opciones de grano. El grano grueso, considera que la suma de las variables del ejemplo se computa y se asigna en único paso. Por otro lado, el paralelismo de grano fino considera que en un primer paso se lee el valor almacenado en $var1$, en un segundo paso se procede del mismo modo con $var2$, en un tercer paso se computaría la suma de ambos valores y, por último, en un cuarto paso se asignaría el resultado a $var$.\\

Claramente, el número de interleavings con grano fino será mayor que con una política de grano grueso. ¿Cuál de estas dos por tanto es la que se suele usar? Depende. Las implementaciones reales de los ordenadores actuales suelen considerar un paralelismo de grano fino. Por ejemplo, los procesadores que soportan un conjunto de instrucciones de ARM, solo permiten operar con valores guardados en registro y por tanto deben realizar cada uno de los pasos anteriores contando el cargar valores de memoria a registro o viceversa más la ejecución de una instrucción aritmética. Este es el caso también de algunos lenguajes de programación como C/C++ o Java.\\

También existe la posibilidad de controlar este comportamiento en un lenguaje de alto nivel en el que se garantice un grano grueso de paralelismo. De hecho, si aislamos la memoria de cada uno de los hilos de programa, el comportamiento de cualquiera de los dos granos es indiferente. Pero, ¿qué sentido tiene que cada uno de los hilos se ejecute con su propia región de memoria? Por si solo no tiene mucho sentido. Lo único que tendríamos son varios programas secuenciales que no interaccionan entre ellos y que a efectos teóricos no cuentan con ninguna concurrencia.\\

No obstante, ¿qué ocurre si somos capaces de hacer que cada hilo sea capaz de comunicarse con el resto de secuencias mandando valores por un canal? En ese caso, sí tenemos algo más interesante. Este concepto es conocido como paso de mensajes.\\

Cada hilo de ejecución ahora podrá en un momento dado escuchar el canal o escribir en él y modificar su comportamiento según los mensajes que reciba. Seguimos por tanto contando con los mismos problemas de la concurrencia reduciendo eso sí el número de interleavings a tener en cuenta.\\

Imaginemos ahora que los mensajes mandados entre objetos son los que provocan la ejecución de los métodos que estos contienen. Esta es la idea en los modelos de concurrencia basados en actores.\\

En estos modelos, cada objeto ejecuta sus tareas de forma concurrente con respecto a las del resto de objetos con la única restricción de que cada objeto solo puede ejecutar una única tarea a la vez. El resto de tareas esperan en una cola cuyo orden en principio no es determinable. El paso de mensajes indica qué método desea ejecutar un objeto (pudiendo ser uno propio o perteneciente a otro objeto) y, dependiendo del tipo de llamada, una tarea puede dejar paso a otra si aún no cuenta con los valores necesarios para proseguir.\\

Se trata de una concurrencia donde el scheduler o planificador no puede desasignar a una tarea dentro de un objeto si esta no ha terminado o si no ha llegado a un punto de espera, funcionando cada objeto como una especie de monitor.\\

En este tipo de concurrencia se basan muchos lenguajes de programación como por ejemplo Erlang y Scala, además de ABS, el que va a ser nuestro compañero de viaje en este trabajo.\\

La motivación de este trabajo es la creación de un lenguaje de programación básico, llamado CABS, que permita recrear una concurrencia entre procesos a nivel de grano fino y sobre el que podamos emplear las potentes herramientas ya elaboradas para el lenguaje ABS en la materia del análisis de programas concurrentes. CABS será un lenguaje de programación con una sintaxis parecida a la de C con tipado estricto y estático, que incluye la posibilidad de usar funciones y arrays y que se mueve en el paradigma de la programación imperativa.\\

Sobre esta temática se han hecho ya trabajos similares de creación de lenguajes o compiladores como en \cite{Alicia}. En dicho trabajo, se abordo la detección de deadlocks en un lenguaje básico que contaba con primitivas para declarar procesos y cerrojos y que empleaba la herramienta SACO desarrollada para ABS sobre una traducción formal. De un modo similar, en nuestro trabajo emplearemos las mismas técnicas formales sobre semánticas para demostrar que la traducción que se propondrá para CABS en efecto cumple con la preservación de todos los interleavings posibles y que, por tanto, los estados finales alcanzables ejecutando CABS con su semántica son los mismos que obtendríamos con ABS. A diferencia de \cite{Alicia}, nuestro trabajo pretende llegar a desarrollar un lenguaje de programación Turing completo sobre el que se puedan implementar algoritmos y no restringirnos a crear una demostración meramente académica sobre la posibilidad de obtener los entrelazamientos en un lengueje de prueba.\\

De un modo similar al que se pretende hacer con CABS, en los años 80 se creo SPIN \footnote{\url{https://en.wikipedia.org/wiki/SPIN_model_checker}}. SPIN es una herramienta de verificación de sistemas distribuidos desarrollada por Gerard J. Holzmann que trabajaba sobre modelos escritos en Promela \footnote{\url{https://en.wikipedia.org/wiki/Promela}}, un lenguaje de modelado, que era traducido a C. Era sobre el código en C donde se empleaban distintas técnicas de verificación, entre las que se incluía el uso de \emph{Partial Order Reduction} (POR). En este aspecto, nosotros podremos aprovechar la heramiento SYCO, disponible para ABS y que implementa técnicas avanzadas de \emph{Dynamic Partial Order Reduction} (DPOR). Sobre esta herramienta dedicaremos un capítulo completo al final de este trabajo. El objetivo de DPOR es conseguir reducir el número de estados de exploración necesarios para conocer los posibles resultados finales de un programa. Como hemos visto en los ejemplos anteriores, existen ocasiones en que el orden en la ejecución de dos instrucciones pertenecientes a procesos distintos no influye en el resultado final del programa y es en este aspecto donde DPOR consigue determinar que ordenes son redundantes para intentar salvar la explosión exponencial de estados intermedios.\\

En los siguientes capítulos describiremos la sintaxis y semántica de nuestro lenguaje así como la del lenguaje ABS sobre el que realizaremos la traducción de CABS. Posteriormente se demostrará la idea de la corrección de la traducción, lo que nos permitirá extrapolar las propiedades del código ABS traducido al código original en CABS. Entre estas propiedades pueden encontrarse las resultantes del uso de herramientas formales desarrolladas sobre ABS. Por último hablaremos de la implementación de esta traducción en un compilador de CABS a ABS desarrollado en Java usando JLex y CUP, herramientas empleadas en la asignatura de Procesadores del Lenguaje.\\

¡Comencemos!
